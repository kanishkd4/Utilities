{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downloaded from https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of parallelizing a slow function on a dataframe that fits in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runnning a spacy function on a pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1804874, 45)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is such an urgent design problem; kudos to you for taking it on. Very impressive!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is this something I'll be able to install on my site? When will you be releasing it?</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target  \\\n",
       "0  59848  0.000000   \n",
       "1  59849  0.000000   \n",
       "2  59852  0.000000   \n",
       "3  59855  0.000000   \n",
       "4  59856  0.893617   \n",
       "\n",
       "                                                                                                         comment_text  \\\n",
       "0               This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!   \n",
       "1  Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!   \n",
       "2                              This is such an urgent design problem; kudos to you for taking it on. Very impressive!   \n",
       "3                                Is this something I'll be able to install on my site? When will you be releasing it?   \n",
       "4                                                                                haha you guys are a bunch of losers.   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
       "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
       "\n",
       "   ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "0  ...        2006  rejected      0    0    0      0         0   \n",
       "1  ...        2006  rejected      0    0    0      0         0   \n",
       "2  ...        2006  rejected      0    0    0      0         0   \n",
       "3  ...        2006  rejected      0    0    0      0         0   \n",
       "4  ...        2006  rejected      0    0    0      1         0   \n",
       "\n",
       "   sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "0              0.0                         0                         4  \n",
       "1              0.0                         0                         4  \n",
       "2              0.0                         0                         4  \n",
       "3              0.0                         0                         4  \n",
       "4              0.0                         4                        47  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An expensive function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train.head(50_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 45)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 33min 18s, sys: 4min 21s, total: 1h 37min 40s\n",
      "Wall time: 12min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc = {}\n",
    "for i, text in enumerate(train_sample.comment_text):\n",
    "    doc[i] = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:59887\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>16.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:59887' processes=4 cores=8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, progress\n",
    "from dask import delayed\n",
    "\n",
    "# Create a client to parallelize all dask functions.\n",
    "client = Client(n_workers=4, threads_per_worker=2, memory_limit='4GB')\n",
    "client\n",
    "\n",
    "# The client will kill the worker and restart it if the memory for any worker exceeds the limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delayed_nlp(df, col=\"comment_text\"):\n",
    "    doc_dict = {}\n",
    "    for i, text in enumerate(df[col]):\n",
    "        doc_dict[i] = nlp(text)\n",
    "    \n",
    "    return doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dask = dd.from_pandas(train_sample, npartitions=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meta in map_partitions needs a dataframe that matches the dtypes and column names. The dataframe can be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanishk.dogar/anaconda3/lib/python3.7/site-packages/distributed/worker.py:3165: UserWarning: Large object of size 2.14 MB detected in task graph: \n",
      "  (           id    target  \\\n",
      "18750  265153  0.00000 ... efb2fc9242db0')\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  % (format_bytes(len(b)), s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 46.6 s, total: 2min 18s\n",
      "Wall time: 7min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_output = train_dask.map_partitions(delayed_nlp, meta=train.head())\n",
    "doc_dict = doc_output.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_dict) # equal to the number of dataframe partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 220 ms, sys: 73.8 ms, total: 294 ms\n",
      "Wall time: 579 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(doc_dict)):\n",
    "    train_dict[i] = train_dask.get_partition(i).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.62 s, sys: 38.4 ms, total: 3.65 s\n",
      "Wall time: 3.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(doc_dict)):\n",
    "    train_dict[i][\"spacy_nlp\"] = doc_dict[i].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict[0].loc[0, \"spacy_nlp\"]\n",
    "type(train_dict[0].loc[0, \"spacy_nlp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'is',\n",
       "  'lemma': 'be',\n",
       "  'NE': '',\n",
       "  'POS_fine': 'VBZ',\n",
       "  'POS_coarse': 'VERB',\n",
       "  'arc': 'ROOT',\n",
       "  'modifiers': [{'word': 'This',\n",
       "    'lemma': 'this',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'DT',\n",
       "    'POS_coarse': 'DET',\n",
       "    'arc': 'nsubj',\n",
       "    'modifiers': []},\n",
       "   {'word': 'cool',\n",
       "    'lemma': 'cool',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'JJ',\n",
       "    'POS_coarse': 'ADJ',\n",
       "    'arc': 'acomp',\n",
       "    'modifiers': [{'word': 'so',\n",
       "      'lemma': 'so',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'RB',\n",
       "      'POS_coarse': 'ADV',\n",
       "      'arc': 'advmod',\n",
       "      'modifiers': []}]},\n",
       "   {'word': '.',\n",
       "    'lemma': '.',\n",
       "    'NE': '',\n",
       "    'POS_fine': '.',\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []}]},\n",
       " {'word': \"'s\",\n",
       "  'lemma': 'be',\n",
       "  'NE': '',\n",
       "  'POS_fine': 'VBZ',\n",
       "  'POS_coarse': 'VERB',\n",
       "  'arc': 'ROOT',\n",
       "  'modifiers': [{'word': 'It',\n",
       "    'lemma': '-PRON-',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'PRP',\n",
       "    'POS_coarse': 'PRON',\n",
       "    'arc': 'nsubj',\n",
       "    'modifiers': []},\n",
       "   {'word': 'like',\n",
       "    'lemma': 'like',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'UH',\n",
       "    'POS_coarse': 'INTJ',\n",
       "    'arc': 'intj',\n",
       "    'modifiers': []},\n",
       "   {'word': ',',\n",
       "    'lemma': ',',\n",
       "    'NE': '',\n",
       "    'POS_fine': ',',\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []},\n",
       "   {'word': \"'\",\n",
       "    'lemma': \"'\",\n",
       "    'NE': '',\n",
       "    'POS_fine': \"''\",\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []},\n",
       "   {'word': 'want',\n",
       "    'lemma': 'want',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'VB',\n",
       "    'POS_coarse': 'VERB',\n",
       "    'arc': 'ccomp',\n",
       "    'modifiers': [{'word': 'would',\n",
       "      'lemma': 'would',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'MD',\n",
       "      'POS_coarse': 'VERB',\n",
       "      'arc': 'aux',\n",
       "      'modifiers': []},\n",
       "     {'word': 'you',\n",
       "      'lemma': '-PRON-',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'PRP',\n",
       "      'POS_coarse': 'PRON',\n",
       "      'arc': 'nsubj',\n",
       "      'modifiers': []},\n",
       "     {'word': 'read',\n",
       "      'lemma': 'read',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'VB',\n",
       "      'POS_coarse': 'VERB',\n",
       "      'arc': 'ccomp',\n",
       "      'modifiers': [{'word': 'mother',\n",
       "        'lemma': 'mother',\n",
       "        'NE': '',\n",
       "        'POS_fine': 'NN',\n",
       "        'POS_coarse': 'NOUN',\n",
       "        'arc': 'nsubj',\n",
       "        'modifiers': [{'word': 'your',\n",
       "          'lemma': '-PRON-',\n",
       "          'NE': '',\n",
       "          'POS_fine': 'PRP$',\n",
       "          'POS_coarse': 'ADJ',\n",
       "          'arc': 'poss',\n",
       "          'modifiers': []}]},\n",
       "       {'word': 'to',\n",
       "        'lemma': 'to',\n",
       "        'NE': '',\n",
       "        'POS_fine': 'TO',\n",
       "        'POS_coarse': 'PART',\n",
       "        'arc': 'aux',\n",
       "        'modifiers': []},\n",
       "       {'word': 'this',\n",
       "        'lemma': 'this',\n",
       "        'NE': '',\n",
       "        'POS_fine': 'DT',\n",
       "        'POS_coarse': 'DET',\n",
       "        'arc': 'dobj',\n",
       "        'modifiers': []}]}]},\n",
       "   {'word': '?',\n",
       "    'lemma': '?',\n",
       "    'NE': '',\n",
       "    'POS_fine': '.',\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []},\n",
       "   {'word': '?',\n",
       "    'lemma': '?',\n",
       "    'NE': '',\n",
       "    'POS_fine': '.',\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []},\n",
       "   {'word': \"'\",\n",
       "    'lemma': \"'\",\n",
       "    'NE': '',\n",
       "    'POS_fine': \"''\",\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []}]},\n",
       " {'word': 'done',\n",
       "  'lemma': 'do',\n",
       "  'NE': '',\n",
       "  'POS_fine': 'VBN',\n",
       "  'POS_coarse': 'VERB',\n",
       "  'arc': 'ROOT',\n",
       "  'modifiers': [{'word': 'idea',\n",
       "    'lemma': 'idea',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'NN',\n",
       "    'POS_coarse': 'NOUN',\n",
       "    'arc': 'nsubjpass',\n",
       "    'modifiers': [{'word': 'great',\n",
       "      'lemma': 'great',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'JJ',\n",
       "      'POS_coarse': 'ADJ',\n",
       "      'arc': 'amod',\n",
       "      'modifiers': [{'word': 'Really',\n",
       "        'lemma': 'really',\n",
       "        'NE': '',\n",
       "        'POS_fine': 'RB',\n",
       "        'POS_coarse': 'ADV',\n",
       "        'arc': 'advmod',\n",
       "        'modifiers': []}]}]},\n",
       "   {'word': ',',\n",
       "    'lemma': ',',\n",
       "    'NE': '',\n",
       "    'POS_fine': ',',\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []},\n",
       "   {'word': 'well',\n",
       "    'lemma': 'well',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'RB',\n",
       "    'POS_coarse': 'ADV',\n",
       "    'arc': 'advmod',\n",
       "    'modifiers': []},\n",
       "   {'word': '!',\n",
       "    'lemma': '!',\n",
       "    'NE': '',\n",
       "    'POS_fine': '.',\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []}]}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict[0].loc[0, \"spacy_nlp\"].print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dictionary back to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 80.8 ms, sys: 45 ms, total: 126 ms\n",
      "Wall time: 125 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.concat(train_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 46)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tree\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'word': 'is',\n",
       "  'lemma': 'be',\n",
       "  'NE': '',\n",
       "  'POS_fine': 'VBZ',\n",
       "  'POS_coarse': 'VERB',\n",
       "  'arc': 'ROOT',\n",
       "  'modifiers': [{'word': 'This',\n",
       "    'lemma': 'this',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'DT',\n",
       "    'POS_coarse': 'DET',\n",
       "    'arc': 'nsubj',\n",
       "    'modifiers': []},\n",
       "   {'word': 'cool',\n",
       "    'lemma': 'cool',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'JJ',\n",
       "    'POS_coarse': 'ADJ',\n",
       "    'arc': 'acomp',\n",
       "    'modifiers': [{'word': 'so',\n",
       "      'lemma': 'so',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'RB',\n",
       "      'POS_coarse': 'ADV',\n",
       "      'arc': 'advmod',\n",
       "      'modifiers': []}]},\n",
       "   {'word': '.',\n",
       "    'lemma': '.',\n",
       "    'NE': '',\n",
       "    'POS_fine': '.',\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []}]},\n",
       " {'word': \"'s\",\n",
       "  'lemma': 'be',\n",
       "  'NE': '',\n",
       "  'POS_fine': 'VBZ',\n",
       "  'POS_coarse': 'VERB',\n",
       "  'arc': 'ROOT',\n",
       "  'modifiers': [{'word': 'It',\n",
       "    'lemma': '-PRON-',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'PRP',\n",
       "    'POS_coarse': 'PRON',\n",
       "    'arc': 'nsubj',\n",
       "    'modifiers': []},\n",
       "   {'word': 'like',\n",
       "    'lemma': 'like',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'UH',\n",
       "    'POS_coarse': 'INTJ',\n",
       "    'arc': 'intj',\n",
       "    'modifiers': []},\n",
       "   {'word': ',',\n",
       "    'lemma': ',',\n",
       "    'NE': '',\n",
       "    'POS_fine': ',',\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []},\n",
       "   {'word': \"'\",\n",
       "    'lemma': \"'\",\n",
       "    'NE': '',\n",
       "    'POS_fine': \"''\",\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []},\n",
       "   {'word': 'want',\n",
       "    'lemma': 'want',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'VB',\n",
       "    'POS_coarse': 'VERB',\n",
       "    'arc': 'ccomp',\n",
       "    'modifiers': [{'word': 'would',\n",
       "      'lemma': 'would',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'MD',\n",
       "      'POS_coarse': 'VERB',\n",
       "      'arc': 'aux',\n",
       "      'modifiers': []},\n",
       "     {'word': 'you',\n",
       "      'lemma': '-PRON-',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'PRP',\n",
       "      'POS_coarse': 'PRON',\n",
       "      'arc': 'nsubj',\n",
       "      'modifiers': []},\n",
       "     {'word': 'read',\n",
       "      'lemma': 'read',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'VB',\n",
       "      'POS_coarse': 'VERB',\n",
       "      'arc': 'ccomp',\n",
       "      'modifiers': [{'word': 'mother',\n",
       "        'lemma': 'mother',\n",
       "        'NE': '',\n",
       "        'POS_fine': 'NN',\n",
       "        'POS_coarse': 'NOUN',\n",
       "        'arc': 'nsubj',\n",
       "        'modifiers': [{'word': 'your',\n",
       "          'lemma': '-PRON-',\n",
       "          'NE': '',\n",
       "          'POS_fine': 'PRP$',\n",
       "          'POS_coarse': 'ADJ',\n",
       "          'arc': 'poss',\n",
       "          'modifiers': []}]},\n",
       "       {'word': 'to',\n",
       "        'lemma': 'to',\n",
       "        'NE': '',\n",
       "        'POS_fine': 'TO',\n",
       "        'POS_coarse': 'PART',\n",
       "        'arc': 'aux',\n",
       "        'modifiers': []},\n",
       "       {'word': 'this',\n",
       "        'lemma': 'this',\n",
       "        'NE': '',\n",
       "        'POS_fine': 'DT',\n",
       "        'POS_coarse': 'DET',\n",
       "        'arc': 'dobj',\n",
       "        'modifiers': []}]}]},\n",
       "   {'word': '?',\n",
       "    'lemma': '?',\n",
       "    'NE': '',\n",
       "    'POS_fine': '.',\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []},\n",
       "   {'word': '?',\n",
       "    'lemma': '?',\n",
       "    'NE': '',\n",
       "    'POS_fine': '.',\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []},\n",
       "   {'word': \"'\",\n",
       "    'lemma': \"'\",\n",
       "    'NE': '',\n",
       "    'POS_fine': \"''\",\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []}]},\n",
       " {'word': 'done',\n",
       "  'lemma': 'do',\n",
       "  'NE': '',\n",
       "  'POS_fine': 'VBN',\n",
       "  'POS_coarse': 'VERB',\n",
       "  'arc': 'ROOT',\n",
       "  'modifiers': [{'word': 'idea',\n",
       "    'lemma': 'idea',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'NN',\n",
       "    'POS_coarse': 'NOUN',\n",
       "    'arc': 'nsubjpass',\n",
       "    'modifiers': [{'word': 'great',\n",
       "      'lemma': 'great',\n",
       "      'NE': '',\n",
       "      'POS_fine': 'JJ',\n",
       "      'POS_coarse': 'ADJ',\n",
       "      'arc': 'amod',\n",
       "      'modifiers': [{'word': 'Really',\n",
       "        'lemma': 'really',\n",
       "        'NE': '',\n",
       "        'POS_fine': 'RB',\n",
       "        'POS_coarse': 'ADV',\n",
       "        'arc': 'advmod',\n",
       "        'modifiers': []}]}]},\n",
       "   {'word': ',',\n",
       "    'lemma': ',',\n",
       "    'NE': '',\n",
       "    'POS_fine': ',',\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []},\n",
       "   {'word': 'well',\n",
       "    'lemma': 'well',\n",
       "    'NE': '',\n",
       "    'POS_fine': 'RB',\n",
       "    'POS_coarse': 'ADV',\n",
       "    'arc': 'advmod',\n",
       "    'modifiers': []},\n",
       "   {'word': '!',\n",
       "    'lemma': '!',\n",
       "    'NE': '',\n",
       "    'POS_fine': '.',\n",
       "    'POS_coarse': 'PUNCT',\n",
       "    'arc': 'punct',\n",
       "    'modifiers': []}]}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"spacy_nlp\"][0]\n",
    "\n",
    "print(\"\\n Tree\")\n",
    "train_df[\"spacy_nlp\"][0].print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "      <th>spacy_nlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>(This, is, so, cool, ., It, 's, like, ,, ', would, you, want, your, mother, to, read, this, ?, ?, ', Really, great, idea, ,, well, done, !)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>(Thank, you, !, !, This, would, make, my, life, a, lot, less, anxiety, -, inducing, ., Keep, it, up, ,, and, do, n't, let, anyone, get, in, your, way, !)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is such an urgent design problem; kudos to you for taking it on. Very impressive!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>(This, is, such, an, urgent, design, problem, ;, kudos, to, you, for, taking, it, on, ., Very, impressive, !)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is this something I'll be able to install on my site? When will you be releasing it?</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>(Is, this, something, I, 'll, be, able, to, install, on, my, site, ?, When, will, you, be, releasing, it, ?)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>(haha, you, guys, are, a, bunch, of, losers, .)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target  \\\n",
       "0  59848  0.000000   \n",
       "1  59849  0.000000   \n",
       "2  59852  0.000000   \n",
       "3  59855  0.000000   \n",
       "4  59856  0.893617   \n",
       "\n",
       "                                                                                                         comment_text  \\\n",
       "0               This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!   \n",
       "1  Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!   \n",
       "2                              This is such an urgent design problem; kudos to you for taking it on. Very impressive!   \n",
       "3                                Is this something I'll be able to install on my site? When will you be releasing it?   \n",
       "4                                                                                haha you guys are a bunch of losers.   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
       "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
       "\n",
       "   ...    rating  funny  wow  sad  likes  disagree  sexual_explicit  \\\n",
       "0  ...  rejected      0    0    0      0         0              0.0   \n",
       "1  ...  rejected      0    0    0      0         0              0.0   \n",
       "2  ...  rejected      0    0    0      0         0              0.0   \n",
       "3  ...  rejected      0    0    0      0         0              0.0   \n",
       "4  ...  rejected      0    0    0      1         0              0.0   \n",
       "\n",
       "   identity_annotator_count  toxicity_annotator_count  \\\n",
       "0                         0                         4   \n",
       "1                         0                         4   \n",
       "2                         0                         4   \n",
       "3                         0                         4   \n",
       "4                         4                        47   \n",
       "\n",
       "                                                                                                                                                   spacy_nlp  \n",
       "0                (This, is, so, cool, ., It, 's, like, ,, ', would, you, want, your, mother, to, read, this, ?, ?, ', Really, great, idea, ,, well, done, !)  \n",
       "1  (Thank, you, !, !, This, would, make, my, life, a, lot, less, anxiety, -, inducing, ., Keep, it, up, ,, and, do, n't, let, anyone, get, in, your, way, !)  \n",
       "2                                              (This, is, such, an, urgent, design, problem, ;, kudos, to, you, for, taking, it, on, ., Very, impressive, !)  \n",
       "3                                               (Is, this, something, I, 'll, be, able, to, install, on, my, site, ?, When, will, you, be, releasing, it, ?)  \n",
       "4                                                                                                            (haha, you, guys, are, a, bunch, of, losers, .)  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
